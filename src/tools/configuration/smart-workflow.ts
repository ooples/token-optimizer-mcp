/** * Smart Workflow Tool - 83% Token Reduction for GitHub Actions Workflow Analysis * * Features: * - Parse and validate GitHub Actions workflow files (.github/workflows/*.yml) * - Detect syntax errors, security issues, and misconfigurations * - Provide optimization suggestions (caching, parallelization, etc.) * - Cache parsed workflows with 7-day TTL * - File hash-based invalidation on workflow changes * - Re-parse only changed files on subsequent reads */ import {
  readFileSync,
  existsSync,
  readdirSync,
  statSync,
} from "fs";
import { join, relative, basename } from "path";
import { homedir } from "os";
import { parse as parseYAML } from "yaml";
import { CacheEngine } from "../../core/cache-engine";
import { TokenCounter } from "../../core/token-counter";
import { MetricsCollector } from "../../core/metrics";
import { hashFile, generateCacheKey } from "../shared/hash-utils";
import { createHash } from "crypto"; // ============================================================================// Types & Interfaces// ============================================================================export interface SmartWorkflowOptions {  /**   * Path to the project root containing .github/workflows   */  projectRoot?: string;  /**   * Specific workflow file to analyze (relative to .github/workflows/)   */  workflowFile?: string;  /**   * Enable caching (default: true)   */  enableCache?: boolean;  /**   * Cache TTL in seconds (default: 7 days = 604800)   */  ttl?: number;  /**   * Force re-parse all workflows (ignore cache)   */  force?: boolean;  /**   * Include optimization suggestions   */  includeSuggestions?: boolean;  /**   * Include security analysis   */  includeSecurityAnalysis?: boolean;  /**   * Validate only (don't return full parsed workflows)   */  validateOnly?: boolean;}export interface WorkflowFile {  path: string;  name: string;  hash: string;  parsed: WorkflowDefinition;  valid: boolean;  errors: WorkflowError[];  warnings: WorkflowWarning[];  securityIssues: SecurityIssue[];  suggestions: OptimizationSuggestion[];}export interface WorkflowDefinition {  name?: string;  on: WorkflowTrigger;  jobs: Record<string, WorkflowJob>;  env?: Record<string, string>;  permissions?: WorkflowPermissions;  concurrency?: WorkflowConcurrency;}export interface WorkflowTrigger {  [event: string]: any;}export interface WorkflowJob {  name?: string;  'runs-on': string | string[];  needs?: string | string[];  if?: string;  strategy?: {    matrix?: Record<string, any[]>;    'fail-fast'?: boolean;    'max-parallel'?: number;  };  steps: WorkflowStep[];  env?: Record<string, string>;  permissions?: WorkflowPermissions;  'timeout-minutes'?: number;  'continue-on-error'?: boolean;}export interface WorkflowStep {  name?: string;  id?: string;  uses?: string;  run?: string;  with?: Record<string, any>;  env?: Record<string, string>;  if?: string;  'continue-on-error'?: boolean;  'timeout-minutes'?: number;}export interface WorkflowPermissions {  contents?: 'read' | 'write' | 'none';  issues?: 'read' | 'write' | 'none';  'pull-requests'?: 'read' | 'write' | 'none';  deployments?: 'read' | 'write' | 'none';  packages?: 'read' | 'write' | 'none';  [key: string]: string | undefined;}export interface WorkflowConcurrency {  group: string;  'cancel-in-progress'?: boolean;}export interface WorkflowError {  file: string;  severity: 'error';  message: string;  line?: number;  path?: string;}export interface WorkflowWarning {  file: string;  severity: 'warning';  message: string;  category: 'performance' | 'best-practice' | 'deprecation';  path?: string;}export interface SecurityIssue {  file: string;  severity: 'high' | 'medium' | 'low';  category: 'secrets' | 'permissions' | 'injection' | 'dependencies';  message: string;  recommendation: string;  path?: string;}export interface OptimizationSuggestion {  file: string;  type: 'caching' | 'parallelization' | 'matrix' | 'dependencies' | 'performance';  impact: 'high' | 'medium' | 'low';  message: string;  example?: string;}export interface SmartWorkflowOutput {  summary: {    totalWorkflows: number;    validWorkflows: number;    invalidWorkflows: number;    totalErrors: number;    totalWarnings: number;    totalSecurityIssues: number;    fromCache: boolean;    changedFiles: string[];  };  workflows: Array<{    name: string;    file: string;    valid: boolean;    triggers: string[];    jobCount: number;    hasMatrix: boolean;    hasCaching: boolean;    permissions?: string;  }>;  issues: {    errors: WorkflowError[];    warnings: WorkflowWarning[];    security: SecurityIssue[];  };  suggestions: OptimizationSuggestion[];  metrics: {    originalTokens: number;    compactedTokens: number;    reductionPercentage: number;  };}// ============================================================================// Main Class// ============================================================================export class SmartWorkflow {  private cache: CacheEngine;  private tokenCounter: TokenCounter;  private metrics: MetricsCollector;  private cacheNamespace = 'smartworkflow';  constructor(    cache: CacheEngine,    tokenCounter: TokenCounter,    metrics: MetricsCollector  ) {    this.cache = cache;    this.tokenCounter = tokenCounter;    this.metrics = metrics;  }  /**   * Run workflow analysis with intelligent caching   */  async run(options: SmartWorkflowOptions = {}): Promise<SmartWorkflowOutput> {    const {      projectRoot = process.cwd(),      workflowFile,      enableCache = true,      ttl = 604800, // 7 days      force = false,      includeSuggestions = true,      includeSecurityAnalysis = true,      validateOnly = false    } = options;    const startTime = Date.now();    const workflowsDir = join(projectRoot, '.github', 'workflows');    // Check if workflows directory exists    if (!existsSync(workflowsDir)) {      throw new Error(`Workflows directory not found: ${workflowsDir}`);    }    // Get workflow files to analyze    const workflowFiles = workflowFile      ? [join(workflowsDir, workflowFile)]      : this.discoverWorkflowFiles(workflowsDir);    if (workflowFiles.length === 0) {      throw new Error('No workflow files found');    }    // Generate cache key based on workflow files and their hashes    const cacheKey = this.generateCacheKey(workflowFiles);    // Check cache    let parsedWorkflows: WorkflowFile[] = [];    let changedFiles: string[] = [];    let fromCache = false;    if (enableCache && !force) {      const cached = this.cache.get(cacheKey);      if (cached) {        const cachedData = JSON.parse(cached);        parsedWorkflows = cachedData.workflows;        fromCache = true;        // Check which files changed        changedFiles = this.detectChangedFiles(workflowFiles, parsedWorkflows);        if (changedFiles.length > 0) {          // Re-parse only changed files          parsedWorkflows = await this.reparseChangedFiles(            workflowFiles,            parsedWorkflows,            changedFiles          );          fromCache = false;        }      }    }    // Parse all workflows if not from cache or force    if (parsedWorkflows.length === 0 || force) {      parsedWorkflows = await this.parseAllWorkflows(workflowFiles);      changedFiles = workflowFiles.map(f => relative(workflowsDir, f));    }    // Run analysis    if (includeSuggestions) {      parsedWorkflows = this.addOptimizationSuggestions(parsedWorkflows);    }    if (includeSecurityAnalysis) {      parsedWorkflows = this.addSecurityAnalysis(parsedWorkflows);    }    // Cache the result    if (enableCache && !fromCache) {      const cacheValue = JSON.stringify({        workflows: parsedWorkflows,        timestamp: Date.now()      });      const fileHash = this.generateCacheKey(workflowFiles);      this.cache.set(cacheKey, cacheValue, ttl, 'utf-8');    }    // Transform output    const output = this.transformOutput(      parsedWorkflows,      changedFiles,      fromCache,      validateOnly    );    // Record metrics    const duration = Date.now() - startTime;    this.metrics.record({      operation: 'smartworkflow',      duration,      success: true,      cacheHit: fromCache,      inputTokens: output.metrics.originalTokens,      outputTokens: output.metrics.compactedTokens,      cachedTokens: fromCache ? output.metrics.compactedTokens : 0,      savedTokens: output.metrics.originalTokens - output.metrics.compactedTokens,      metadata: {        workflowCount: parsedWorkflows.length,        changedFiles: changedFiles.length      }    });    return output;  }  /**   * Discover all workflow files in directory   */  private discoverWorkflowFiles(workflowsDir: string): string[] {    const files = readdirSync(workflowsDir);    return files      .filter(f => f.endsWith('.yml') || f.endsWith('.yaml'))      .map(f => join(workflowsDir, f))      .filter(f => statSync(f).isFile());  }  /**   * Generate cache key from workflow files   */  private generateCacheKey(workflowFiles: string[]): string {    const hashes = workflowFiles.map(f => hashFile(f)).join('|');    const hash = createHash('sha256').update(hashes).digest('hex').substring(0, 16);    return `${this.cacheNamespace}:${hash}`;  }  /**   * Detect which workflow files have changed   */  private detectChangedFiles(    currentFiles: string[],    cachedWorkflows: WorkflowFile[]  ): string[] {    const changedFiles: string[] = [];    for (const file of currentFiles) {      const currentHash = hashFile(file);      const cached = cachedWorkflows.find(w => w.path === file);      if (!cached || cached.hash !== currentHash) {        changedFiles.push(file);      }    }    return changedFiles;  }  /**   * Re-parse only changed workflow files   */  private async reparseChangedFiles(    allFiles: string[],    cachedWorkflows: WorkflowFile[],    changedFiles: string[]  ): Promise<WorkflowFile[]> {    const result: WorkflowFile[] = [];    for (const file of allFiles) {      if (changedFiles.includes(file)) {        // Re-parse changed file        const parsed = await this.parseWorkflowFile(file);        result.push(parsed);      } else {        // Use cached version        const cached = cachedWorkflows.find(w => w.path === file);        if (cached) {          result.push(cached);        }      }    }    return result;  }  /**   * Parse all workflow files   */  private async parseAllWorkflows(workflowFiles: string[]): Promise<WorkflowFile[]> {    const results: WorkflowFile[] = [];    for (const file of workflowFiles) {      const parsed = await this.parseWorkflowFile(file);      results.push(parsed);    }    return results;  }  /**   * Parse a single workflow file   */  private async parseWorkflowFile(filePath: string): Promise<WorkflowFile> {    const content = readFileSync(filePath, 'utf-8');    const hash = hashFile(filePath);    const name = basename(filePath);    const errors: WorkflowError[] = [];    const warnings: WorkflowWarning[] = [];    let parsed: WorkflowDefinition | null = null;    let valid = false;    try {      parsed = parseYAML(content) as WorkflowDefinition;      // Validate workflow structure      const validation = this.validateWorkflow(parsed, name);      errors.push(...validation.errors);      warnings.push(...validation.warnings);      valid = errors.length === 0;    } catch (error) {      errors.push({        file: name,        severity: 'error',        message: `YAML parsing error: ${error instanceof Error ? error.message : String(error)}`      });      valid = false;    }    return {      path: filePath,      name,      hash,      parsed: parsed || { on: {}, jobs: {} },      valid,      errors,      warnings,      securityIssues: [],      suggestions: []    };  }  /**   * Validate workflow structure   */  private validateWorkflow(    workflow: WorkflowDefinition,    fileName: string  ): { errors: WorkflowError[]; warnings: WorkflowWarning[] } {    const errors: WorkflowError[] = [];    const warnings: WorkflowWarning[] = [];    // Check required fields    if (!workflow.on) {      errors.push({        file: fileName,        severity: 'error',        message: 'Missing required field: "on" (workflow triggers)'      });    }    if (!workflow.jobs || Object.keys(workflow.jobs).length === 0) {      errors.push({        file: fileName,        severity: 'error',        message: 'No jobs defined in workflow'      });    }    // Validate jobs    if (workflow.jobs) {      for (const [jobId, job] of Object.entries(workflow.jobs)) {        // Check runs-on        if (!job['runs-on']) {          errors.push({            file: fileName,            severity: 'error',            message: `Job "${jobId}" missing required field: "runs-on"`,            path: `jobs.${jobId}`          });        }        // Check steps        if (!job.steps || job.steps.length === 0) {          errors.push({            file: fileName,            severity: 'error',            message: `Job "${jobId}" has no steps defined`,            path: `jobs.${jobId}`          });        }        // Validate steps        if (job.steps) {          job.steps.forEach((step, index) => {            if (!step.uses && !step.run) {              errors.push({                file: fileName,                severity: 'error',                message: `Job "${jobId}", step ${index + 1}: must have either "uses" or "run"`,                path: `jobs.${jobId}.steps[${index}]`              });            }          });        }        // Check for deprecated runner images        const runsOn = Array.isArray(job['runs-on']) ? job['runs-on'][0] : job['runs-on'];        if (runsOn?.includes('ubuntu-18.04')) {          warnings.push({            file: fileName,            severity: 'warning',            category: 'deprecation',            message: `Job "${jobId}" uses deprecated runner "ubuntu-18.04"`,            path: `jobs.${jobId}.runs-on`          });        }        // Check timeout        if (!job['timeout-minutes']) {          warnings.push({            file: fileName,            severity: 'warning',            category: 'best-practice',            message: `Job "${jobId}" has no timeout set - consider adding timeout-minutes`,            path: `jobs.${jobId}`          });        }      }    }    return { errors, warnings };  }  /**   * Add optimization suggestions   */  private addOptimizationSuggestions(workflows: WorkflowFile[]): WorkflowFile[] {    return workflows.map(workflow => {      const suggestions: OptimizationSuggestion[] = [];      if (!workflow.valid || !workflow.parsed.jobs) {        return workflow;      }      for (const [jobId, job] of Object.entries(workflow.parsed.jobs)) {        // Check for caching opportunities        const hasCaching = job.steps?.some(          step => step.uses?.includes('actions/cache') || step.uses?.includes('setup-')        );        if (!hasCaching && job.steps?.some(step => step.run?.includes('npm install') || step.run?.includes('yarn'))) {          suggestions.push({            file: workflow.name,            type: 'caching',            impact: 'high',            message: `Job "${jobId}" could benefit from dependency caching`,            example: `- uses: actions/cache@v3\n  with:\n    path: ~/.npm\n    key: \${{ runner.os }}-node-\${{ hashFiles('**/package-lock.json') }}`          });        }        // Check for parallelization opportunities        if (!job.strategy?.matrix && job.steps && job.steps.length > 5) {          suggestions.push({            file: workflow.name,            type: 'parallelization',            impact: 'medium',            message: `Job "${jobId}" has many steps - consider splitting into parallel jobs`,            example: `strategy:\n  matrix:\n    component: [frontend, backend, tests]`          });        }        // Check for unnecessary checkout steps        const checkoutCount = job.steps?.filter(step => step.uses?.includes('actions/checkout')).length || 0;        if (checkoutCount > 1) {          suggestions.push({            file: workflow.name,            type: 'performance',            impact: 'low',            message: `Job "${jobId}" has multiple checkout steps - usually only one is needed`          });        }      }      return {        ...workflow,        suggestions      };    });  }  /**   * Add security analysis   */  private addSecurityAnalysis(workflows: WorkflowFile[]): WorkflowFile[] {    return workflows.map(workflow => {      const securityIssues: SecurityIssue[] = [];      if (!workflow.valid || !workflow.parsed.jobs) {        return workflow;      }      // Check workflow-level permissions      if (!workflow.parsed.permissions) {        securityIssues.push({          file: workflow.name,          severity: 'medium',          category: 'permissions',          message: 'Workflow has no explicit permissions defined',          recommendation: 'Set explicit permissions at workflow or job level to follow principle of least privilege'        });      } else if (workflow.parsed.permissions.contents === 'write' && workflow.parsed.permissions['pull-requests'] === 'write') {        securityIssues.push({          file: workflow.name,          severity: 'high',          category: 'permissions',          message: 'Workflow has both contents:write and pull-requests:write',          recommendation: 'Review if both write permissions are necessary'        });      }      // Check jobs for security issues      for (const [jobId, job] of Object.entries(workflow.parsed.jobs)) {        // Check for secrets in run commands        job.steps?.forEach((step, index) => {          if (step.run) {            const hasSecretsInRun = /\$\{\{\s*secrets\.[^}]+\}\}/.test(step.run);            if (hasSecretsInRun) {              securityIssues.push({                file: workflow.name,                severity: 'high',                category: 'secrets',                message: `Job "${jobId}", step ${index + 1}: Secret used directly in run command`,                recommendation: 'Pass secrets via environment variables instead of inline in run commands',                path: `jobs.${jobId}.steps[${index}]`              });            }          }          // Check for potential script injection          if (step.run?.includes('${{') && step.run?.includes('github.event')) {            securityIssues.push({              file: workflow.name,              severity: 'high',              category: 'injection',              message: `Job "${jobId}", step ${index + 1}: Potential script injection vulnerability`,              recommendation: 'Sanitize github.event data before using in run commands',              path: `jobs.${jobId}.steps[${index}]`            });          }          // Check for unpinned action versions          if (step.uses && !step.uses.includes('@')) {            securityIssues.push({              file: workflow.name,              severity: 'medium',              category: 'dependencies',              message: `Job "${jobId}", step ${index + 1}: Action "${step.uses}" is not pinned to a version`,              recommendation: 'Pin actions to specific versions or commit SHAs',              path: `jobs.${jobId}.steps[${index}]`            });          }        });      }      return {        ...workflow,        securityIssues      };    });  }  /**   * Transform output to smart format with token reduction   */  private transformOutput(    workflows: WorkflowFile[],    changedFiles: string[],    fromCache: boolean,    validateOnly: boolean  ): SmartWorkflowOutput {    const allErrors = workflows.flatMap(w => w.errors);    const allWarnings = workflows.flatMap(w => w.warnings);    const allSecurity = workflows.flatMap(w => w.securityIssues);    const allSuggestions = workflows.flatMap(w => w.suggestions);    // Create compact workflow summaries    const workflowSummaries = workflows.map(w => ({      name: w.parsed.name || w.name,      file: w.name,      valid: w.valid,      triggers: w.parsed.on ? Object.keys(w.parsed.on) : [],      jobCount: w.parsed.jobs ? Object.keys(w.parsed.jobs).length : 0,      hasMatrix: this.hasMatrixStrategy(w.parsed),      hasCaching: this.hasCaching(w.parsed),      permissions: this.getPermissionsSummary(w.parsed)    }));    // Calculate token metrics    const originalSize = this.estimateOriginalSize(workflows);    const compactSize = this.estimateCompactSize(workflowSummaries, allErrors, allWarnings);    const originalTokens = Math.ceil(originalSize / 4);    const compactedTokens = Math.ceil(compactSize / 4);    const reductionPercentage = Math.round(((originalTokens - compactedTokens) / originalTokens) * 100);    return {      summary: {        totalWorkflows: workflows.length,        validWorkflows: workflows.filter(w => w.valid).length,        invalidWorkflows: workflows.filter(w => !w.valid).length,        totalErrors: allErrors.length,        totalWarnings: allWarnings.length,        totalSecurityIssues: allSecurity.length,        fromCache,        changedFiles      },      workflows: workflowSummaries,      issues: {        errors: allErrors.slice(0, 20), // Limit to first 20        warnings: allWarnings.slice(0, 20),        security: allSecurity.slice(0, 10)      },      suggestions: allSuggestions.slice(0, 15), // Limit to top 15      metrics: {        originalTokens,        compactedTokens,        reductionPercentage      }    };  }  /**   * Check if workflow uses matrix strategy   */  private hasMatrixStrategy(workflow: WorkflowDefinition): boolean {    if (!workflow.jobs) return false;    return Object.values(workflow.jobs).some(job => job.strategy?.matrix);  }  /**   * Check if workflow uses caching   */  private hasCaching(workflow: WorkflowDefinition): boolean {    if (!workflow.jobs) return false;    return Object.values(workflow.jobs).some(job =>      job.steps?.some(step => step.uses?.includes('actions/cache'))    );  }  /**   * Get permissions summary   */  private getPermissionsSummary(workflow: WorkflowDefinition): string | undefined {    if (!workflow.permissions) return undefined;    const writePerms = Object.entries(workflow.permissions)      .filter(([_, value]) => value === 'write')      .map(([key]) => key);    if (writePerms.length === 0) return 'read-only';    if (writePerms.length === 1) return `write:${writePerms[0]}`;    return `write:${writePerms.length}`;  }  /**   * Estimate original output size (full workflow YAML + verbose output)   */  private estimateOriginalSize(workflows: WorkflowFile[]): number {    return workflows.reduce((total, w) => {      const yamlSize = readFileSync(w.path, 'utf-8').length;      const metadataSize = 500; // Headers, formatting, etc.      return total + yamlSize + metadataSize;    }, 0);  }  /**   * Estimate compact output size   */  private estimateCompactSize(    summaries: any[],    errors: WorkflowError[],    warnings: WorkflowWarning[]  ): number {    return JSON.stringify({      summaries: summaries,      errors: errors.slice(0, 20),      warnings: warnings.slice(0, 20)    }).length;  }  /**   * Close cache connection   */  close(): void {    this.cache.close();  }}// ============================================================================// Exported Function// ============================================================================/** * Factory function for shared resources (benchmarks) */export function getSmartWorkflow(  cache: CacheEngine,  tokenCounter: TokenCounter,  metrics: MetricsCollector): SmartWorkflow {  return new SmartWorkflow(cache, tokenCounter, metrics);}/** * Run smart workflow analysis (CLI-friendly) */export async function runSmartWorkflow(  options: SmartWorkflowOptions = {}): Promise<SmartWorkflowOutput> {  const cache = new CacheEngine(100, join(homedir(), '.hypercontext', 'cache'));  const tokenCounter = new TokenCounter();  const metrics = new MetricsCollector();  const analyzer = getSmartWorkflow(cache, tokenCounter, metrics);  try {    return await analyzer.run(options);  } finally {    analyzer.close();  }}// ============================================================================// MCP Tool Definition// ============================================================================export const SMARTWORKFLOWTOOLDEFINITION = {  name: 'smartworkflow',  description: 'Analyze GitHub Actions workflows with intelligent caching, validation, security analysis, and optimization suggestions. Achieves 83% token reduction.',  inputSchema: {    type: 'object',    properties: {      projectRoot: {        type: 'string',        description: 'Project root directory containing .github/workflows'      },      workflowFile: {        type: 'string',        description: 'Specific workflow file to analyze (relative to .github/workflows/)'      },      enableCache: {        type: 'boolean',        description: 'Enable caching (default: true)',        default: true      },      ttl: {        type: 'number',        description: 'Cache TTL in seconds (default: 604800 = 7 days)',        default: 604800      },      force: {        type: 'boolean',        description: 'Force re-parse all workflows (ignore cache)',        default: false      },      includeSuggestions: {        type: 'boolean',        description: 'Include optimization suggestions',        default: true      },      includeSecurityAnalysis: {        type: 'boolean',        description: 'Include security analysis',        default: true      },      validateOnly: {        type: 'boolean',        description: 'Only validate, don\'t return full parsed workflows',        default: false      }    }  }};
