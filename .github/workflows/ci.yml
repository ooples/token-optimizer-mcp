name: CI

on:
  pull_request:
    branches: [ master ]
  push:
    branches: [ master ]

# Cancel in-progress runs for the same workflow and branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint-and-format:
    name: Lint and Format Check
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        run: npm run lint

      - name: Check Prettier formatting
        run: npm run format:check

      - name: Validate package.json
        run: npm run build --dry-run || true

  build:
    name: Build
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build TypeScript
        run: npm run build

      - name: Verify build artifacts
        run: |
          if [ ! -d "dist" ]; then
            echo "Error: dist directory not created"
            exit 1
          fi
          if [ ! -f "dist/server/index.js" ]; then
            echo "Error: dist/server/index.js not found"
            exit 1
          fi
          echo "Build artifacts verified successfully"

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-${{ github.sha }}
          path: dist/
          retention-days: 7

  test:
    name: Test (Node ${{ matrix.node-version }})
    runs-on: ubuntu-latest
    timeout-minutes: 15

    strategy:
      matrix:
        node-version: ['18', '20', '22']
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run tests with coverage
        run: npm run test:ci
        env:
          NODE_OPTIONS: --experimental-vm-modules

      - name: Generate coverage report
        if: matrix.node-version == '20'
        run: npm run test:coverage
        env:
          NODE_OPTIONS: --experimental-vm-modules

      - name: Upload coverage to Codecov
        if: matrix.node-version == '20'
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage/coverage-final.json
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Check coverage threshold
        if: matrix.node-version == '20'
        run: |
          npm run test:coverage
          if [ $? -ne 0 ]; then
            echo "Error: Coverage threshold not met (minimum 80%)"
            exit 1
          fi
        env:
          NODE_OPTIONS: --experimental-vm-modules

      - name: Upload coverage artifacts
        if: matrix.node-version == '20' && always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-${{ github.sha }}
          path: coverage/
          retention-days: 7

  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build project
        run: npm run build

      - name: Run benchmark suite
        id: benchmark
        run: |
          if [ -f "package.json" ] && npm run --silent test:benchmark 2>/dev/null; then
            npm run test:benchmark | tee benchmark-results.txt
          else
            echo "Benchmark suite not yet implemented, creating placeholder results"
            echo '{"status": "not_implemented", "message": "Benchmark suite to be implemented"}' > benchmark-results.txt
          fi

      - name: Compare against baseline
        id: compare
        run: |
          BASELINE_FILE=".github/performance-baseline.json"

          if [ ! -f "$BASELINE_FILE" ]; then
            echo "No baseline found, creating initial baseline"
            echo "performance_check=new_baseline" >> $GITHUB_OUTPUT
            exit 0
          fi

          # This is a placeholder for actual benchmark comparison logic
          # In a real implementation, you would parse benchmark-results.txt and compare
          echo "performance_check=passed" >> $GITHUB_OUTPUT
          echo "Performance check passed (comparison logic to be implemented)"

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: benchmark-results.txt
          retention-days: 30

      - name: Comment PR with performance results
        if: github.event_name == 'pull_request' && steps.compare.outputs.performance_check != 'new_baseline'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let results = 'Performance benchmarks completed.';

            if (fs.existsSync('benchmark-results.txt')) {
              results = fs.readFileSync('benchmark-results.txt', 'utf8');
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Performance Benchmark Results\n\n\`\`\`\n${results}\n\`\`\``
            });

  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: build

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist-${{ github.sha }}
          path: dist/

      - name: Start MCP server
        run: |
          # Start the server in the background
          npm start &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV

          # Wait for server to be ready (max 30 seconds)
          echo "Waiting for server to start..."
          for i in {1..30}; do
            if nc -z localhost 3000 2>/dev/null; then
              echo "Server is ready!"
              break
            fi
            sleep 1
          done
        timeout-minutes: 2

      - name: Run integration tests
        run: |
          if [ -f "package.json" ] && npm run --silent test:integration 2>/dev/null; then
            npm run test:integration
          else
            echo "Integration tests not yet implemented, skipping"
            exit 0
          fi
        env:
          NODE_OPTIONS: --experimental-vm-modules

      - name: Stop MCP server
        if: always()
        run: |
          if [ -n "$SERVER_PID" ]; then
            kill $SERVER_PID || true
          fi

      - name: Upload integration test logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-logs-${{ github.sha }}
          path: |
            *.log
            logs/
          retention-days: 7

  status-check:
    name: All Checks Passed
    runs-on: ubuntu-latest
    needs: [lint-and-format, build, test, performance-benchmarks, integration-test]
    if: always()

    steps:
      - name: Check all job statuses
        run: |
          if [ "${{ needs.lint-and-format.result }}" != "success" ]; then
            echo "Lint and format check failed"
            exit 1
          fi
          if [ "${{ needs.build.result }}" != "success" ]; then
            echo "Build failed"
            exit 1
          fi
          if [ "${{ needs.test.result }}" != "success" ]; then
            echo "Tests failed"
            exit 1
          fi
          if [ "${{ needs.performance-benchmarks.result }}" != "success" ]; then
            echo "Performance benchmarks failed"
            exit 1
          fi
          if [ "${{ needs.integration-test.result }}" != "success" ]; then
            echo "Integration tests failed"
            exit 1
          fi
          echo "All checks passed!"
